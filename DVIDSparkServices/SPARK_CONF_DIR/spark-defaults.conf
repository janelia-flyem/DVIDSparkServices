##
## This is a modified copy of Ken's spark-defaults.conf
## /usr/local/spark-versions/spark-2.2.0-bin-without-hadoop/conf/spark-defaults.conf
##

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
spark.rpc.askTimeout=300s
spark.storage.blockManagerHeartBeatMs=30000
spark.rpc.retry.wait=30s
spark.kryoserializer.buffer.max=1024m
spark.core.connection.ack.wait.timeout=600s
spark.driver.maxResultSize=0
spark.python.worker.memory=1536m
spark.driver.memory=70g
#spark.executor.memory=25g
#spark.executor.cores=5

#modified by Ken Carlile 5/11/16 to add memory flags (80g/worker/executor, 70g/driver, 1536m/pythonworker)
#modified by Ken Carlile 6/15/16 to split to 3 executors/nodes 25g/executor,5cores/executor,no change pythonworker)
#modified by Ken Carlile 8/29/16 to remove old akka lines


##
## Modifications for FlyEM DVIDSparkServices:
##

# Except for these two settings, which we customized for our jobs
spark.executor.memory=80g
spark.executor.cores=16

# Don't show the console progress bars, since they pollute
# our log files with garbage and terminal control characters
spark.ui.showConsoleProgress=false
